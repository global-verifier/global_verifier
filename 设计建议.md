# gloal_verifier 项目设计建议

## 架构改进

### 1. 模块化设计

```python
# agent/base_agent.py
class BaseAgent:
    """所有 agent 的基础类"""
    def __init__(self, model):
        self.model = model
        
    def predict(self, state, available_actions):
        """统一接口：预测下一步动作"""
        raise NotImplementedError

# agent/qwen_agent.py
class QwenAgent(BaseAgent):
    def predict(self, state, available_actions):
        # Qwen 特定的实现
        pass
```

### 2. 配置集中管理

```python
# config.py
class Config:
    # 环境配置
    ENV = {
        "max_steps": 20,
        "observation_mode": "text_rich"
    }
    
    # 模型配置
    MODELS = {
        "llama3": {
            "path": "/home/xingkun/local_model/Meta-Llama-3-8B-Instruct",
            "device": "cuda",
            "dtype": "float16"
        },
        "qwen2.5": {
            "path": "/home/xingkun/local_model/Qwen2.5-7B-Instruct",
            "device": "cuda",
            "dtype": "float16"
        },
        "qwen3": {
            "path": "/home/xingkun/local_model/Qwen3-8B",
            "device": "cuda",
            "dtype": "float16"
        }
    }
    
    # 评估配置
    EVALUATION = {
        "test_splits": {
            "train": (500, None),
            "eval": (0, 500),
            "test": (0, 500)
        },
        "metrics": ["success_rate", "avg_reward", "avg_steps"]
    }
```

### 3. 实验管理

```python
# evaluator/experiment_runner.py
class ExperimentRunner:
    def __init__(self):
        self.results = {}
        
    def run_comparison(self, models, test_set):
        """运行多个模型的对比实验"""
        for model_name in models:
            agent = self._create_agent(model_name)
            results = self._evaluate(agent, test_set)
            self.results[model_name] = results
            
    def generate_report(self):
        """生成对比报告"""
        # 生成表格、图表等
        pass
```

## 设计原则

### 1. 可扩展性 ✅
- **问题**：新增模型需要修改多处代码
- **解决**：使用工厂模式 + 配置文件

```python
# models/model_factory.py
class ModelFactory:
    @staticmethod
    def create(model_name):
        config = Config.MODELS[model_name]
        if "qwen" in model_name:
            return QwenModel(**config)
        elif "llama" in model_name:
            return LlamaModel(**config)
```

### 2. 可测试性 ✅
```python
# tests/test_agent.py
def test_agent_prediction():
    """测试 agent 预测逻辑"""
    agent = MockAgent()  # 使用 mock 避免加载真实模型
    actions = agent.predict(state="test", actions=["search", "click"])
    assert actions in ["search", "click"]
```

### 3. 可观测性 ✅
```python
# utils/logger.py
class ExperimentLogger:
    def log_episode(self, model_name, episode_id, actions, reward):
        """记录每个 episode 的详细信息"""
        self.log({
            "model": model_name,
            "episode": episode_id,
            "actions": actions,
            "reward": reward,
            "timestamp": time.time()
        })
```

## 最佳实践（来自 WebShop 分析）

### 1. 数据加载
```python
# 参考 web_agent_site/engine/engine.py
def load_goals(filepath, num_products=None):
    """统一的数据加载接口"""
    # 1. 加载原始数据
    # 2. 过滤和预处理
    # 3. 构建索引
    # 4. 返回标准格式
    pass
```

### 2. 状态管理
```python
# 参考 web_agent_text_env.py
class SessionManager:
    """管理 session 状态"""
    def __init__(self):
        self.sessions = {}
        
    def create_session(self, session_id, goal):
        self.sessions[session_id] = {
            'goal': goal,
            'done': False,
            'actions': [],
            'observations': []
        }
    
    def update_session(self, session_id, action, observation):
        self.sessions[session_id]['actions'].append(action)
        self.sessions[session_id]['observations'].append(observation)
```

### 3. 错误处理
```python
# 参考 QwenAgent 的加载逻辑
try:
    model = load_model(path)
except ModelLoadError:
    # 降级到 CPU
    model = load_model(path, device="cpu")
except Exception as e:
    # 记录详细错误信息
    logger.error(f"Failed to load model: {e}")
    raise
```

## 推荐的文件结构

```
gloal_verifier/
├── config.py                 # 统一配置
├── main.py                   # 主入口
│
├── agent/                    # Agent 实现
│   ├── base_agent.py
│   ├── qwen_agent.py
│   ├── llama_agent.py
│   └── __init__.py
│
├── models/                   # 模型管理
│   ├── model_factory.py
│   ├── model_loader.py
│   └── __init__.py
│
├── evaluator/                # 评估模块
│   ├── experiment_runner.py
│   ├── metrics.py
│   └── __init__.py
│
├── utils/                    # 工具函数
│   ├── logger.py
│   ├── visualization.py
│   └── __init__.py
│
├── data/                     # 数据
│   ├── goals/
│   └── results/
│
└── tests/                    # 测试
    ├── test_agent.py
    └── test_evaluator.py
```

## 实现优先级

1. **P0 - 核心功能**
   - ✅ 模型加载（已有）
   - ✅ WebShop 环境集成（已有）
   - ⏳ 统一的 agent 接口

2. **P1 - 评估系统**
   - ⏳ 批量评估脚本
   - ⏳ 结果统计和对比
   - ⏳ 日志记录

3. **P2 - 优化**
   - ⏳ 结果可视化
   - ⏳ 超参数调优
   - ⏳ 错误分析

## 关键决策点

### 1. 如何比较模型？
- **选项 A**：同一组 test cases 轮流测试
- **选项 B**：随机采样不同 test cases
- **推荐**：选项 A（公平对比）

### 2. 如何存储结果？
- **选项 A**：JSON 文件
- **选项 B**：数据库
- **推荐**：选项 A（简单）+ 定期导出到数据库

### 3. 如何可视化？
- **推荐**：使用 wandb 或 tensorboard 实时跟踪

## 避免的陷阱

1. ❌ 不要在每次 reset 时重新加载模型
2. ❌ 不要硬编码模型路径
3. ❌ 不要在 agent 里直接访问环境内部状态
4. ✅ 使用接口隔离（如 WebShop 的 gym 接口）
5. ✅ 保持配置与代码分离
6. ✅ 添加适当的日志

## 参考 WebShop 的优秀设计

1. **Session 管理**：每个 session 独立的 goal
2. **状态重置**：清晰的 reset 逻辑
3. **评分系统**：模块化的 reward 计算
4. **Distance 系统**：支持好任务（数据分离：train/valid/test）
