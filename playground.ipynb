{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6b5fdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingkun/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 4 files: 100%|██████████| 4/4 [01:58<00:00, 29.70s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7493, 0.0751],\n",
      "        [0.0880, 0.6318]])\n"
     ]
    }
   ],
   "source": [
    "# Requires transformers>=4.51.0\n",
    "# Requires sentence-transformers>=2.7.0\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"Qwen/Qwen3-Embedding-8B\")\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving,\n",
    "# together with setting `padding_side` to \"left\":\n",
    "# model = SentenceTransformer(\n",
    "#     \"Qwen/Qwen3-Embedding-8B\",\n",
    "#     model_kwargs={\"attn_implementation\": \"flash_attention_2\", \"device_map\": \"auto\"},\n",
    "#     tokenizer_kwargs={\"padding_side\": \"left\"},\n",
    "# )\n",
    "\n",
    "# The queries and documents to embed\n",
    "queries = [\n",
    "    \"What is the capital of China?\",\n",
    "    \"Explain gravity\",\n",
    "]\n",
    "documents = [\n",
    "    \"The capital of China is Beijing.\",\n",
    "    \"Gravity is a force that attracts two bodies towards each other. It gives weight to physical objects and is responsible for the movement of planets around the sun.\",\n",
    "]\n",
    "\n",
    "# Encode the queries and documents. Note that queries benefit from using a prompt\n",
    "# Here we use the prompt called \"query\" stored under `model.prompts`, but you can\n",
    "# also pass your own prompt via the `prompt` argument\n",
    "query_embeddings = model.encode(queries, prompt_name=\"query\")\n",
    "document_embeddings = model.encode(documents)\n",
    "\n",
    "# Compute the (cosine) similarity between the query and document embeddings\n",
    "similarity = model.similarity(query_embeddings, document_embeddings)\n",
    "print(similarity)\n",
    "# tensor([[0.7493, 0.0751],\n",
    "#         [0.0880, 0.6318]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b39879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85bd8a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84ccca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = model.encode(\"left\")\n",
    "right = model.encode(\"right\")\n",
    "good = model.encode(\"good\")\n",
    "bad = model.encode(\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d3013f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good, right: tensor([[0.7324]])\n",
      "good, bad: tensor([[0.8374]])\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity between left and right\n",
    "cosine_similarity = model.similarity(good, right)\n",
    "print(f\"good, right: {cosine_similarity}\")\n",
    "\n",
    "# Calculate cosine similarity between left and right\n",
    "cosine_similarity = model.similarity(good, bad)\n",
    "print(f\"good, bad: {cosine_similarity}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f93e9654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    import numpy as np\n",
    "    a = a / (np.linalg.norm(a) + 1e-12)\n",
    "    b = b / (np.linalg.norm(b) + 1e-12)\n",
    "    return float(np.dot(a, b))\n",
    "\n",
    "def mean_pool(last_hidden_state, attention_mask):\n",
    "    # last_hidden_state: [B, T, H], mask: [B, T]\n",
    "    import torch\n",
    "    mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)  # [B, T, 1]\n",
    "    summed = (last_hidden_state * mask).sum(dim=1)                  # [B, H]\n",
    "    counts = mask.sum(dim=1).clamp(min=1e-9)                        # [B, 1]\n",
    "    return summed / counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cb04d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8373851180076599"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(good, bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38867785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good, bad: tensor([[0.8947]])\n",
      "bad, hot_e5: tensor([[0.8106]])\n"
     ]
    }
   ],
   "source": [
    "# Use E5-large-v2 to check cosine similarity between good and bad\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# Load E5-large-v2 model\n",
    "e5_model = SentenceTransformer('intfloat/e5-large-v2')\n",
    "\n",
    "# Encode \"good\" and \"bad\"\n",
    "good_e5 = e5_model.encode(\"good\")\n",
    "bad_e5 = e5_model.encode(\"bad\")\n",
    "hot_e5 = e5_model.encode(\"hot\")\n",
    "cold_e5 = e5_model.encode(\"cold\")\n",
    "\n",
    "# Calculate cosine similarity using the model's similarity function\n",
    "print(f\"good, bad: {e5_model.similarity(good_e5, bad_e5)}\")\n",
    "print(f\"bad, hot_e5: {e5_model.similarity(good_e5, hot_e5)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "847a0e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name princeton-nlp/unsup-simcse-bert-large-uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimCSE - good和bad之间的cosine similarity: tensor([[0.7198]])\n",
      "SimCSE - good和nice之间的cosine similarity: tensor([[0.5724]])\n"
     ]
    }
   ],
   "source": [
    "# Use SimCSE to check cosine similarity between good and bad\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load SimCSE model\n",
    "simcse_model = SentenceTransformer('princeton-nlp/unsup-simcse-bert-large-uncased')\n",
    "\n",
    "# Encode \"good\" and \"bad\"\n",
    "good_simcse = simcse_model.encode(\"good\")\n",
    "bad_simcse = simcse_model.encode(\"bad\")\n",
    "nice_simcse = simcse_model.encode(\"nice\")\n",
    "\n",
    "# Calculate cosine similarity  the model's similarity function\n",
    "similarity_simcse = simcse_model.similarity(good_simcse, bad_simcse)\n",
    "print(f\"SimCSE - good和bad之间的cosine similarity: {similarity_simcse}\")\n",
    "\n",
    "# Calculate cosine similarity  the model's similarity function\n",
    "similarity_simcse = simcse_model.similarity(good_simcse, nice_simcse)\n",
    "print(f\"SimCSE - good和nice之间的cosine similarity: {similarity_simcse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ba5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to install the spaCy English model\n",
    "# Uncomment the line below and run this cell\n",
    "\n",
    "# !pip install --user https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e28015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a94c7c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases:\n",
      "  - We\n",
      "  - retrieval augmented generation and ice cream\n",
      "  - examples\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Install spaCy model if not already installed\n",
    "# Run this if you get an error: python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"We use retrieval augmented generation and ice cream as examples.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "print(\"Noun phrases:\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(f\"  - {chunk.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0582923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
